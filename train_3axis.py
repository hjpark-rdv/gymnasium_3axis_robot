import gymnasium as gym
import numpy as np
import pybullet as p
import pybullet_data
from gymnasium import spaces
from stable_baselines3 import PPO
from stable_baselines3.common.env_checker import check_env
import os

from stable_baselines3.common.monitor import Monitor
import matplotlib.pyplot as plt
import numpy as np
from stable_baselines3.common.callbacks import BaseCallback
from datetime import datetime
import csv
class LivePlotCallback(BaseCallback):
    """
    í•™ìŠµ ì¤‘ ì‹¤ì‹œê°„ ë³´ìƒ ê·¸ë˜í”„ë¥¼ ì—…ë°ì´íŠ¸í•˜ê³  ë³´ìƒì„ CSV íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” ì½œë°± í´ë˜ìŠ¤
    """
    def __init__(self, update_freq=1000, log_dir="./training_logs"):
        super(LivePlotCallback, self).__init__()
        self.update_freq = update_freq
        self.rewards = []
        self.log_dir = log_dir

        # âœ… ë¡œê·¸ ì €ì¥ í´ë” ìƒì„±
        os.makedirs(self.log_dir, exist_ok=True)

        # âœ… í˜„ì¬ ì‹œê°„ ê¸°ë°˜ íŒŒì¼ëª… ìƒì„± (ì˜ˆ: "training_logs/2025_02_23_11_22_33_rewards.csv")
        self.log_file = os.path.join(self.log_dir, f"{datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}_rewards.csv")

        # âœ… CSV íŒŒì¼ ìƒì„± (í—¤ë” ì¶”ê°€)
        with open(self.log_file, mode="w", newline="") as file:
            writer = csv.writer(file)
            writer.writerow(["Step", "Mean Reward"])  # ì»¬ëŸ¼ í—¤ë” ì¶”ê°€

        # Matplotlib ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œ í™œì„±í™”
        plt.ion()
        self.fig, self.ax = plt.subplots(figsize=(8, 5))
        self.line, = self.ax.plot([], [], label="Episode Reward")

        self.ax.set_xlabel("Training Iterations")
        self.ax.set_ylabel("Mean Reward")
        self.ax.set_title("Live Training Progress")
        self.ax.legend()
        plt.show()

    def _on_step(self) -> bool:
        # ì¼ì • stepë§ˆë‹¤ ë³´ìƒì„ ê·¸ë˜í”„ì— ì—…ë°ì´íŠ¸ & CSVì— ì €ì¥
        if self.n_calls % self.update_freq == 0:
            # episode_rewards = np.mean(self.training_env.get_attr("last_reward"))  # âœ… ì˜¬ë°”ë¥¸ ë³´ìƒê°’ ê°€ì ¸ì˜¤ê¸°
            episode_rewards = self.locals['rewards'] if 'rewards' in self.locals else 0
            self.rewards.append(episode_rewards)

            
            # âœ… CSVì— ë³´ìƒ ë°ì´í„° ì €ì¥
            with open(self.log_file, mode="a", newline="") as file:
                writer = csv.writer(file)
                writer.writerow([self.n_calls, episode_rewards])

            # ê·¸ë˜í”„ ì—…ë°ì´íŠ¸
            self.line.set_xdata(range(len(self.rewards)))
            self.line.set_ydata(self.rewards)
            self.ax.relim()
            self.ax.autoscale_view()

            plt.draw()
            plt.pause(0.1)  # ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸

        return True

class CartesianRobotEnv(gym.Env):
    def __init__(self):
        super(CartesianRobotEnv, self).__init__()

        # ê´€ì ˆì˜ ìœ„ì¹˜ í•œê³„ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
        self.joint_limits = {
            'joint_x': (-1.0, 1.0),
            'joint_y': (-1.0, 1.0),
            'joint_z': (-1.0, 1.0)
        }

        # ê´€ì ˆì˜ ì´ˆê¸° ìœ„ì¹˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
        self.joint_positions = {
            'joint_x': 0.0,
            'joint_y': 0.0,
            'joint_z': 0.0
        }

        # ê´€ì ˆì˜ ì´ë¦„ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        self.joint_names = list(self.joint_positions.keys())

        # ê´€ì ˆì˜ ê°œìˆ˜ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
        self.num_joints = len(self.joint_names)

        # ê´€ì ˆì˜ ìœ„ì¹˜ì™€ ì†ë„ë¥¼ ê´€ì°°ê°’ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
        self.observation_space = spaces.Box(
            low=np.array([self.joint_limits[j][0] for j in self.joint_names] + [-np.inf] * self.num_joints),
            high=np.array([self.joint_limits[j][1] for j in self.joint_names] + [np.inf] * self.num_joints),
            dtype=np.float32
        )

        # ê° ê´€ì ˆì— ëŒ€í•œ í˜ì„ ì•¡ì…˜ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
        self.action_space = spaces.Box(
            low=np.array([-1.0] * self.num_joints),
            high=np.array([1.0] * self.num_joints),
            dtype=np.float32
        )

        # PyBullet ë¬¼ë¦¬ ì‹œë®¬ë ˆì´í„°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        # self.physics_client = p.connect(p.GUI)
        self.physics_client = p.connect(p.DIRECT)
        p.setAdditionalSearchPath(pybullet_data.getDataPath())
        p.setGravity(0, 0, -9.81)

     
        # p.connect(p.GUI)
        # p.setAdditionalSearchPath(pybullet_data.getDataPath())


        # plane_id = p.loadURDF("plane.urdf")

        # ë¡œë´‡ URDF íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.
 # self.robot_id = p.loadURDF("robot_description/3dof_cartesian_robot.urdf")
        current_dir = os.path.dirname(os.path.abspath(__file__))
        urdf_path = os.path.join(current_dir, "robot_description/3dof_cartesian_robot.urdf")

        self.robot_id = p.loadURDF(urdf_path, useFixedBase=True)
        # ê° ê´€ì ˆì˜ ì¸ë±ìŠ¤ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
        self.joint_indices = {self.joint_names[i]: i for i in range(self.num_joints)}

        p.setPhysicsEngineParameter(numSolverIterations=150)
        p.setTimeStep(1./1000.)
        
        self.target_position = np.random.uniform(low=[0.5, 0.3, 0.2], high=[0.9, 0.7, 0.6])

    def reset(self, seed=None, options=None):
        super().reset(seed=seed)

        # ì´ˆê¸° ëª©í‘œ ì¢Œí‘œ ì„¤ì •
        # self.target_position = np.random.uniform(low=[0.5, 0.3, 0.2], high=[0.9, 0.7, 0.6])

        # ê¸°ì¡´ ëª©í‘œ ì˜¤ë¸Œì íŠ¸ ì‚­ì œ í›„ ìƒˆë¡œ ìƒì„±
        if hasattr(self, "target_visual_id"):
            p.removeBody(self.target_visual_id)
        
        visual_shape_id = p.createVisualShape(shapeType=p.GEOM_SPHERE, radius=0.05, rgbaColor=[1, 0, 0, 1])
        self.target_visual_id = p.createMultiBody(baseVisualShapeIndex=visual_shape_id, basePosition=self.target_position)

        # ì¡°ì¸íŠ¸ ì´ˆê¸°í™” (í•œê³„ë¥¼ ë„˜ì§€ ì•Šë„ë¡ ì„¤ì •)
        for joint_name in self.joint_names:
            joint_index = self.joint_indices[joint_name]
            initial_position = (self.joint_limits[joint_name][0] + self.joint_limits[joint_name][1]) / 2

            p.resetJointState(self.robot_id, joint_index, targetValue=initial_position)

        return self._get_observation(), {}

    def step(self, action):
        """
        X, Y, Zê°€ ë¶€ëª¨ ë§í¬ì—ì„œ ë¶„ë¦¬ë˜ì§€ ì•Šë„ë¡, ë¶€ëª¨ ë§í¬ì˜ ìœ„ì¹˜ë¥¼ ê°•ì œ ë°˜ì˜í•˜ì—¬ ì„¤ì •.
        """
        # í˜„ì¬ ê° ì¡°ì¸íŠ¸ì˜ ìƒíƒœ(ìœ„ì¹˜)ë¥¼ ê°€ì ¸ì˜´
        joint_states = p.getJointStates(self.robot_id, list(self.joint_indices.values()))
        current_positions = {name: joint_states[i][0] for i, name in enumerate(self.joint_names)}

        # ë¶€ëª¨ ë§í¬ ìœ„ì¹˜ ë°˜ì˜í•˜ì—¬ ìƒˆë¡œìš´ ëª©í‘œ ìœ„ì¹˜ ê³„ì‚°
        new_z = max(min(current_positions["joint_z"] + action[2] * 0.05, self.joint_limits["joint_z"][1]), self.joint_limits["joint_z"][0])
        new_y = max(min(current_positions["joint_y"] + action[1] * 0.05, self.joint_limits["joint_y"][1]), self.joint_limits["joint_y"][0]) + new_z
        new_x = max(min(current_positions["joint_x"] + action[0] * 0.05, self.joint_limits["joint_x"][1]), self.joint_limits["joint_x"][0]) + new_y

        # ë¶€ëª¨ ìœ„ì¹˜ë¥¼ ë°˜ì˜í•œ ì¡°ì¸íŠ¸ ìœ„ì¹˜ ì„¤ì •
        p.setJointMotorControl2(self.robot_id, self.joint_indices["joint_z"], controlMode=p.POSITION_CONTROL, targetPosition=new_z, force=100)
        p.setJointMotorControl2(self.robot_id, self.joint_indices["joint_y"], controlMode=p.POSITION_CONTROL, targetPosition=new_y, force=50)
        p.setJointMotorControl2(self.robot_id, self.joint_indices["joint_x"], controlMode=p.POSITION_CONTROL, targetPosition=new_x, force=50)

        # PyBullet ì‹œë®¬ë ˆì´ì…˜ í•œ ìŠ¤í… ì§„í–‰
        p.stepSimulation()

        # ë””ë²„ê¹…ìš© ì¶œë ¥ (ê° ì¡°ì¸íŠ¸ì˜ ìœ„ì¹˜ í™•ì¸)
        print(f"ğŸ”„ Step Debug - Z: {new_z:.3f}, Y: {new_y:.3f}, X: {new_x:.3f}")

        # ê´€ì°°ê°’, ë³´ìƒ, ì¢…ë£Œ ì—¬ë¶€ ë°˜í™˜
        observation = self._get_observation()
        reward = self._compute_reward(observation)
        terminated = self._is_terminated(observation)
        truncated = False

        return observation, reward, terminated, truncated, {}

        # í˜„ì¬ ì¡°ì¸íŠ¸ ìƒíƒœ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
        for i, joint_name in enumerate(self.joint_names):
            joint_index = self.joint_indices[joint_name]
            joint_state = p.getJointState(self.robot_id, joint_index)
            print(f"Joint {joint_name} - Position: {joint_state[0]:.2f}, Velocity: {joint_state[1]:.2f}")

        return observation, reward, terminated, truncated, {}


    def _get_observation(self):
        # ê° ê´€ì ˆì˜ ìœ„ì¹˜ì™€ ì†ë„ë¥¼ ê´€ì°°ê°’ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        joint_states = p.getJointStates(self.robot_id, list(self.joint_indices.values()))
        joint_positions = [state[0] for state in joint_states]
        joint_velocities = [state[1] for state in joint_states]
        return np.array(joint_positions + joint_velocities, dtype=np.float32)
    def _get_end_effector_position(self):
        """
        í˜„ì¬ End-Effector(ë¡œë´‡ íŒ” ë) ìœ„ì¹˜ë¥¼ ê°€ì ¸ì˜´.
        """
        link_state = p.getLinkState(self.robot_id, self.joint_indices["joint_x"])  # Xì¶• ë ìœ„ì¹˜
        end_effector_position = np.array(link_state[0])  # (x, y, z) ì¢Œí‘œ ê°€ì ¸ì˜¤ê¸°
        return end_effector_position
    def _compute_reward(self, observation):
        """
        í˜„ì¬ End-Effector ìœ„ì¹˜ì™€ ëª©í‘œ ìœ„ì¹˜ì˜ ê±°ë¦¬ ì°¨ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë³´ìƒì„ ê³„ì‚°.
        ëª©í‘œì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ì€ ë³´ìƒì„ ì£¼ê³ , ë©€ì–´ì§ˆìˆ˜ë¡ ë³´ìƒì„ ë‚®ì¶˜ë‹¤.
        """
        end_effector_position = self._get_end_effector_position()
        
        # ëª©í‘œ ì¢Œí‘œì™€ í˜„ì¬ ì¢Œí‘œì˜ ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°
        distance_to_target = np.linalg.norm(self.target_position - end_effector_position)

        # ë³´ìƒ ê³„ì‚° (ëª©í‘œì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë³´ìƒì´ ì»¤ì§)
        reward = -distance_to_target  # ê±°ë¦¬ ìì²´ë¥¼ ë³´ìƒìœ¼ë¡œ ì‚¬ìš© (ì‘ì„ìˆ˜ë¡ ë³´ìƒì´ ë†’ìŒ)
        
        return reward

    def _is_terminated(self, observation):
        # ê´€ì ˆì´ í•œê³„ë¥¼ ë²—ì–´ë‚˜ë©´ ì—í”¼ì†Œë“œë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.
        joint_positions = observation[:self.num_joints]
        for i, joint_name in enumerate(self.joint_names):
            if not (self.joint_limits[joint_name][0] <= joint_positions[i] <= self.joint_limits[joint_name][1]):
                return True
        return False

    def render(self, mode='human'):
        pass

    def close(self):
        p.disconnect()

if __name__ == "__main__":
    # í™˜ê²½ì„ ìƒì„±í•©ë‹ˆë‹¤.
    env = CartesianRobotEnv()

    # âœ… í˜„ì¬ ì‹œê°„ì„ ê¸°ë°˜ìœ¼ë¡œ íŒŒì¼ëª… ìƒì„± (ì˜ˆ: "2025_02_23_11_22_33.csv")
    current_time = datetime.now().strftime("%Y_%m_%d_%H_%M_%S")
    log_dir = "./training_logs"
    os.makedirs(log_dir, exist_ok=True)  # í´ë” ìƒì„±

    # âœ… CSV íŒŒì¼ ê²½ë¡œ ì„¤ì •
    log_file = os.path.join(log_dir, f"{current_time}_")

    # âœ… Monitorì— íŒŒì¼ ê²½ë¡œ ì ìš©
    env = Monitor(env, log_file)

    # í™˜ê²½ì´ ì˜¬ë°”ë¥´ê²Œ ì •ì˜ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    check_env(env, warn=True)

    # PPO ì—ì´ì „íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    model = PPO("MlpPolicy", env, verbose=1)
    # ì½œë°±ì„ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ ì¤‘ ì‹¤ì‹œê°„ ê·¸ë˜í”„ í‘œì‹œ
    callback = LivePlotCallback(update_freq=1)
    # ì—ì´ì „íŠ¸ë¥¼ í•™ìŠµì‹œí‚µë‹ˆë‹¤.
    model.learn(total_timesteps=100000, callback=callback)

    # í•™ìŠµëœ ì—ì´ì „íŠ¸ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
    model.save("ppo_cartesian_robot")

    # í™˜ê²½ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.
    env.close()
